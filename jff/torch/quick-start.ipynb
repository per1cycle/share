{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# speed rush to overview torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and print as a matrix using matplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FunNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.conv = torch.nn.Conv3d()\n",
    "        self.hidden = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.hidden(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (hidden): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = FunNet().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define loss function and optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.136415\n",
      "loss: 1.144183\n",
      "loss: 0.957477\n",
      "loss: 1.098169\n",
      "loss: 0.976871\n",
      "loss: 1.007914\n",
      "loss: 1.046949\n",
      "loss: 0.966616\n",
      "loss: 1.013037\n",
      "loss: 0.969064\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.025831\n",
      "loss: 1.053030\n",
      "loss: 0.849836\n",
      "loss: 1.011408\n",
      "loss: 0.894811\n",
      "loss: 0.918665\n",
      "loss: 0.975040\n",
      "loss: 0.897114\n",
      "loss: 0.938172\n",
      "loss: 0.908071\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.944787\n",
      "loss: 0.989560\n",
      "loss: 0.772224\n",
      "loss: 0.949997\n",
      "loss: 0.838980\n",
      "loss: 0.852976\n",
      "loss: 0.923141\n",
      "loss: 0.850465\n",
      "loss: 0.883918\n",
      "loss: 0.863105\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.881918\n",
      "loss: 0.941607\n",
      "loss: 0.713595\n",
      "loss: 0.904025\n",
      "loss: 0.798029\n",
      "loss: 0.803263\n",
      "loss: 0.883007\n",
      "loss: 0.817268\n",
      "loss: 0.842929\n",
      "loss: 0.827559\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.830824\n",
      "loss: 0.902675\n",
      "loss: 0.667263\n",
      "loss: 0.868137\n",
      "loss: 0.766257\n",
      "loss: 0.764459\n",
      "loss: 0.849750\n",
      "loss: 0.792304\n",
      "loss: 0.810694\n",
      "loss: 0.798222\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.787844\n",
      "loss: 0.869198\n",
      "loss: 0.629396\n",
      "loss: 0.839126\n",
      "loss: 0.740118\n",
      "loss: 0.733469\n",
      "loss: 0.821129\n",
      "loss: 0.772443\n",
      "loss: 0.784595\n",
      "loss: 0.773118\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.750780\n",
      "loss: 0.839367\n",
      "loss: 0.597610\n",
      "loss: 0.815058\n",
      "loss: 0.717999\n",
      "loss: 0.708192\n",
      "loss: 0.795498\n",
      "loss: 0.755688\n",
      "loss: 0.762637\n",
      "loss: 0.750969\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.718193\n",
      "loss: 0.812323\n",
      "loss: 0.570384\n",
      "loss: 0.794466\n",
      "loss: 0.698994\n",
      "loss: 0.687165\n",
      "loss: 0.772211\n",
      "loss: 0.741005\n",
      "loss: 0.743629\n",
      "loss: 0.731126\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.689244\n",
      "loss: 0.787413\n",
      "loss: 0.546758\n",
      "loss: 0.776432\n",
      "loss: 0.682382\n",
      "loss: 0.669537\n",
      "loss: 0.750787\n",
      "loss: 0.727862\n",
      "loss: 0.726951\n",
      "loss: 0.713146\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.663383\n",
      "loss: 0.764313\n",
      "loss: 0.526023\n",
      "loss: 0.760259\n",
      "loss: 0.667871\n",
      "loss: 0.654555\n",
      "loss: 0.730971\n",
      "loss: 0.716026\n",
      "loss: 0.712310\n",
      "loss: 0.696733\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.640122\n",
      "loss: 0.742820\n",
      "loss: 0.507626\n",
      "loss: 0.745638\n",
      "loss: 0.655026\n",
      "loss: 0.641739\n",
      "loss: 0.712470\n",
      "loss: 0.705270\n",
      "loss: 0.699405\n",
      "loss: 0.681582\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.619205\n",
      "loss: 0.722880\n",
      "loss: 0.491260\n",
      "loss: 0.732257\n",
      "loss: 0.643752\n",
      "loss: 0.630648\n",
      "loss: 0.695151\n",
      "loss: 0.695605\n",
      "loss: 0.688046\n",
      "loss: 0.667517\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.600355\n",
      "loss: 0.704454\n",
      "loss: 0.476639\n",
      "loss: 0.719940\n",
      "loss: 0.633744\n",
      "loss: 0.620950\n",
      "loss: 0.678999\n",
      "loss: 0.686924\n",
      "loss: 0.678065\n",
      "loss: 0.654495\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.583265\n",
      "loss: 0.687372\n",
      "loss: 0.463455\n",
      "loss: 0.708485\n",
      "loss: 0.624878\n",
      "loss: 0.612480\n",
      "loss: 0.663845\n",
      "loss: 0.679305\n",
      "loss: 0.669428\n",
      "loss: 0.642428\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.567861\n",
      "loss: 0.671728\n",
      "loss: 0.451620\n",
      "loss: 0.697837\n",
      "loss: 0.617063\n",
      "loss: 0.604976\n",
      "loss: 0.649770\n",
      "loss: 0.672713\n",
      "loss: 0.661990\n",
      "loss: 0.631082\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.553792\n",
      "loss: 0.657336\n",
      "loss: 0.440895\n",
      "loss: 0.687858\n",
      "loss: 0.609990\n",
      "loss: 0.598160\n",
      "loss: 0.636693\n",
      "loss: 0.667044\n",
      "loss: 0.655581\n",
      "loss: 0.620420\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.540890\n",
      "loss: 0.644074\n",
      "loss: 0.431109\n",
      "loss: 0.678481\n",
      "loss: 0.603360\n",
      "loss: 0.591940\n",
      "loss: 0.624542\n",
      "loss: 0.662282\n",
      "loss: 0.650107\n",
      "loss: 0.610259\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m train(train_loader, model\u001b[38;5;241m=\u001b[39mmodel, loss_fn\u001b[38;5;241m=\u001b[39mloss_fn, optim\u001b[38;5;241m=\u001b[39moptimizer)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 29\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m---> 29\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m         pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m     31\u001b[0m         test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loss_fn \n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model: torch.nn.Module, loss_fn, optim):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        if batch % 100 == 0:\n",
    "            loss = loss.item()\n",
    "            print(f\"loss: {loss:>7f}\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "epoch = 500\n",
    "for i in range(epoch):\n",
    "    print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "    train(train_loader, model=model, loss_fn=loss_fn, optim=optimizer)\n",
    "    test(test_loader, model=model, loss_fn=loss_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
